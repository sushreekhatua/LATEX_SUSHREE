{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=brown>SUSHREE SADHANA KHATUA\n",
    "    \n",
    "    \n",
    "## <font color= black>INTRODUCTION:</font>\n",
    "***\n",
    "    \n",
    "<font color= blue>I am Sushree Sadhana Khatua and I am from India.I am 28 years old and currently I am staying in Stockholm,Sweden with my family.I am in Sweden from last three years.I can speak Oriya,Hindi,English & Swedish.</font>\n",
    "\n",
    "[<font color=orange>Link to github:</font>](https://sushreekhatua.github.io/)\n",
    "\n",
    "\n",
    "## EDUCATION:\n",
    "***\n",
    "\n",
    "<font color= purple>I did my graduation in engineering & Technology with specialization in **Civil Engineering** with overall cgpa 9/10.Currently I am enrolled in **Data Science & Machine Learning** course at **Integrify International Academy**.This course will cover following area:</font>\n",
    "\n",
    "* Version Control\n",
    "* Data Exploration/Wrangling\n",
    "* Data Visualization\n",
    "* Probability & Statistics\n",
    "* Databases\n",
    "* Cloud Entities\n",
    "* Docker\n",
    "* Keras\n",
    "* Pandas\n",
    "* Numpy\n",
    "* Ploty\n",
    "* Data Analysis\n",
    "* Machine Learning\n",
    "\n",
    "### WHY DATA SCIENCE & MACHINE LEARNING  AT INTEGRIFY? \n",
    "***\n",
    "    \n",
    "<img src=\"https://www.andre-vollrath.de/assets/logos/integrify-logo.png\">\n",
    "\n",
    "<font color= green>Though i am from civil engineering background and have learned building construction technology,my interest for technology and coding push me towards this course.I am at beginning of my career and **Integrify** will make me efficient and structured to start my career in **Data Science & Machine Learning** and **Integrify** is the best platform for me.</font>\n",
    "\n",
    "\n",
    "### HOBBY:\n",
    "***\n",
    "<font color=brown>I like to cook in my freetime.Apart from that i love to listen music and like to play badminton in my spare time.</font>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# **LATEX FORM OF EQUATION**\n",
    "\n",
    "\n",
    "\n",
    "### 1. <font color=orange>Gaussian Distribution Equation:</font>\n",
    "**Gaussian functions** are often used to represent the _probability density function_ of a normally distributed random variable with expected value $\\mu$ =b and _variance_ $\\sigma^2 = c^2$.In this case,the Gaussian is of the form:$$P(x) = \\frac{1}{\\sigma\\sqrt{2x}}e^ { - (x - \\mu)^2} / {2\\sigma^2} $$\n",
    "\n",
    "### 2. <font color=orange>Sigmoid Equation:</font>\n",
    "A **sigmoid function** is a mathematical function having a characteristic \"S\" - shaped curve or **sigmoid curve**.A common example of a sigmoid function is the logistic function and it is defined as:$$S(x) = \\frac{1}{1+e^{-x}} = \\frac{e^x}{e^x+1} = 1-S(-x) $$\n",
    "     \n",
    "### 3. <font color=orange>Mean square error:</font>\n",
    "The **mean squared error (MSE)** of an estimator measures the average of the squares of the errors- that is,the average squared difference between the estimated values and the actual value.\n",
    "The definition of am MSE differs according to whether one is describing a predictor or an estimator.\n",
    "* **For Predictor:**$$MSE = \\frac{1}{n}\\sum\\limits_{i=1}^n(Y_{i}-\\hat{Y}_{i})^2$$\n",
    "* **For Estimator:**$$MSE(\\hat\\theta) = E_{\\theta}\\displaystyle \\Bigg[(\\hat\\theta-\\theta)^2\\Bigg]$$\n",
    "\n",
    "### 4. <font color=orange>Soft max Equation:</font>\n",
    "**Softmax** turns arbitrary real values into probabilities,which are often useful in Machine Learning.\n",
    "1. Raise **e** (the mathematical constant) to the power of each of those numbers.\n",
    "2.Sum up all the exponentials (powers of _e_).This result is the _denominator_.\n",
    "3. Uae each number's exponential as its _numerator_.\n",
    "4. Probability = $\\frac{Numerator}{Denominator}$\n",
    "\n",
    "Written more fancily,Softmax performs the following transform on _n_ numbers$x_{1}$.....$x_{n}$:$$s(x_{i}) = \\frac{e^{x_{i}}}{\\sum\\limits_{j=1}^{n} e^{x_{j}}}$$\n",
    "\n",
    "The outputs of the Softmax transform are always in the range $[0,1]$ and add up to 1.Hence,they form a probability distribution.\n",
    "\n",
    "### 5. <font color=orange>Binomial Formula:</font>\n",
    "The **Binomial Distribution Formula** is used to calculate probability of getting x successes in the n trials of the binomial experiment which are independent and the probability is derived by combination between number of the trials and number of success raised to power of number of successes represented by px which is further multiplied by probability of the failure raised to power of difference between number of success and number of the trials represented by (1-p)n-x.So,\n",
    "$$P(X) ={}_{n}C_{x}p^{x}(1-p)^{n-x}$$\n",
    "\n",
    "### 6.<font color=orange>Bayes Equation:</font>\n",
    "**Bayes'theorem** is stated mathematically as the following equation:$$P(A\\mid B) = \\frac{P(B\\mid A)P(A)}{P(B)}$$\n",
    "where A and B are events and $P(B)\\not= 0$.\n",
    "\n",
    "### 7.<font color=orange>Categorical Crossentropy:</font>\n",
    "**Categorical crossentropy** is a loss function that is used in multi-class classification tasks.These are tasks where an example can only belong to one out of mant possible categories,and the model must decide which one.\n",
    "Formally,it is designed to quantity the difference between two probability distributions.\n",
    "\n",
    "[<font color=green>diagram of Categorical crossentropy](https://peltarion.com/static/categorical_crossentropy_setup.svg)\n",
    "\n",
    "The categorical crossentropy loss function calculates the loss of an example by computing the following sum:$$Loss =-\\sum\\limits_{i=1}^{output size}y_{i}.log \\hat{y_{i}}$$\n",
    "    \n",
    "### 8.<font color=orange>Hessian matrix:</font>\n",
    "A **Hessian matrix** is a **square matrix** whose elements are second-order partial derivatives of a given function.\n",
    "Matrix Form $[H_{f} = \\{\\{f_{xx},f_{xy}\\},\\{f_{yx},f_{yy}\\}\\}]$\n",
    "    $$\\begin{bmatrix} f_{xx} & f_{xy}\\\\ f_{yx} & f_{yy} \\end{bmatrix}$$\n",
    "    \n",
    "### 9.<font color=orange>Cross-correlation:</font>\n",
    "The **Cross-correlation matrix** of two _random vectors_ is a matrix containing as elements the cross-correlations of all pairs of elements of the random vectors.\n",
    " \n",
    "$\\mathrm{R}_{\\mathbf{X Y}} \\triangleq \\mathrm{E}\\left[\\mathbf{X} \\mathbf{Y}^{\\mathrm{T}}\\right]$\n",
    "and has dimensions $m \\times n$. Written component-wise:\n",
    "$$\n",
    "\\mathrm{R}_{\\mathrm{XY}}=\\left[\\begin{array}{cccc}\n",
    "\\mathrm{E}\\left[X_{1} Y_{1}\\right] & \\mathrm{E}\\left[X_{1} Y_{2}\\right] & \\cdots & \\mathrm{E}\\left[X_{1} Y_{n}\\right] \\\\\n",
    "\\mathrm{E}\\left[X_{2} Y_{1}\\right] & \\mathrm{E}\\left[X_{2} Y_{2}\\right] & \\cdots & \\mathrm{E}\\left[X_{2} Y_{n}\\right] \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\mathrm{E}\\left[X_{m} Y_{1}\\right] & \\mathrm{E}\\left[X_{m} Y_{2}\\right] & \\cdots & \\mathrm{E}\\left[X_{m} Y_{n}\\right]\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "    \n",
    "### 10.<font color=orange>QR Decomposition of Normal    Equation:</font>\n",
    "In linear algebra, a **QR decomposition**,also known as **QR factorization** or **QU factorization** is a decomposition of a matrix A into product A =QR of an orthogonal matrix Q and an upper triangular matrix R.\n",
    "\n",
    "\\begin{array}{l}\n",
    "X^{\\wedge} T X b=X^{\\wedge} T y \\\\\n",
    "(Q R)^{\\wedge} T(Q R) \\quad b=(Q R)^{\\wedge} T y \\\\\n",
    "R^{\\wedge} T\\left(Q^{\\wedge} T Q\\right) R b=R^{\\wedge} T Q^{\\wedge} T y \\\\\n",
    "R^{\\wedge} T R b=R^{\\wedge} T Q^{\\wedge} T y \\\\\n",
    "\\left(R^{\\wedge} T\\right)^{\\wedge}\\{-1\\} R^{\\wedge} T R b=\\left(R^{\\wedge} T\\right)^{\\wedge}\\{-1\\} R^{\\wedge} T Q^{\\wedge} T y \\\\\n",
    "R \\quad b=Q^{\\wedge} T y \\\\\n",
    "\\text { If we let } z=Q^{\\wedge} T y \\\\\n",
    "R \\quad b=z\n",
    "\\end{array}\n",
    "    \n",
    "### 11. <font color=orange>Mahalanobis Distance</font>\n",
    "\n",
    "The **Mahalanobis distance** is a measure of the distance between a point P and a distribution D.\n",
    "    \n",
    "    The Mahalanobis distance of an observation from a set of observations with mean covariance matrix S is defined as:\n",
    "$$D_{M}(\\vec{x}) = \\sqrt{(\\vec{x}-\\vec{\\mu})^{T}S^{-1}(\\vec{x}-\\vec{y})}$$\n",
    "    \n",
    " Mahalanobis distance can also be defined as a dissimilarity measure between two random vectors $\\vec{x}$ and $\\vec{y}$ of the same distribution with the _covariance matrix_ S.\n",
    "    $$d(\\vec{x},\\vec{y}) = \\sqrt{(\\vec{x}-\\vec{y})^{T}S^{-1}(\\vec{x}-\\vec{y})}$$\n",
    "    \n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
